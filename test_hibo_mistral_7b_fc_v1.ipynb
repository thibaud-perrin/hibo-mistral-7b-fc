{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMrJBAKHoBrz1NglxMoWTC3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thibaud-perrin/hibo-mistral-7b-fc-v1/blob/main/test_hibo_mistral_7b_fc_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“– hibo-mistral-7b-fc-v1 Testing\n",
        "\n",
        "This notebook focuses on testing the newly saved model `thibaud-perrin/hibo-mistral-7b-fc-v1` from the Hugging Face Hub."
      ],
      "metadata": {
        "id": "SjVvxxRIu4ZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“¦ Installation of Required Packages\n",
        "\n",
        "Similar to the training notebook, we start by installing necessary packages that enable us to work with the model and perform evaluations. The `!pip install` command is used to ensure all dependencies are met for running the tests successfully."
      ],
      "metadata": {
        "id": "tGKl8qwOvF60"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4BphUJau2CV"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q trl xformers sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“š Import of All Required Packages\n",
        "\n",
        "In this step, we import all the libraries and modules required for testing the model. This includes only `transformers`."
      ],
      "metadata": {
        "id": "xMkcyYDDwIYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer"
      ],
      "metadata": {
        "id": "DImo1zF-wIBO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ¤– Loading the New Model and Its Tokenizer\n",
        "\n",
        "We load the `thibaud-perrin/hibo-mistral-7b-fc-v1` model along with its tokenizer from the Hugging Face Hub. This step is crucial for preparing the model for evaluation and ensuring it can process inputs correctly."
      ],
      "metadata": {
        "id": "KEXZCpfqvJ-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace \"AutoModelForCausalLM\" and \"AutoTokenizer\" with specific model and tokenizer classes if necessary\n",
        "model_identifier = \"thibaud-perrin/hibo-mistral-7b-fc-v1\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_identifier)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_identifier)"
      ],
      "metadata": {
        "id": "KCMJ7EaQvL7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.chat_template"
      ],
      "metadata": {
        "id": "uWDhhi1807JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”„ Put Model in Eval Mode\n",
        "\n",
        "Before testing, we switch the model to evaluation mode using the `.eval()` method. This disables training-specific behaviors like dropout, ensuring the model's outputs are consistent and reflective of its true performance."
      ],
      "metadata": {
        "id": "LfN9yS_UvZfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.use_cache = True\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "zZPdIogivaKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ§ª Test the Model\n",
        "\n",
        "Finally, we test the model by running it on specific examples or a test dataset. This allows us to assess how well the model performs on the task it was fine-tuned for, such as instruction following or function calling. The outcomes of these tests can provide insights into any adjustments needed or confirm the model's readiness for deployment."
      ],
      "metadata": {
        "id": "cbdaaiLbwPwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stream(user_prompt):\n",
        "    # runtimeFlag = \"cuda:0\"\n",
        "    runtimeFlag = \"cpu\"\n",
        "    system_prompt = \"\"\"You are a helpful assistant with access to the following functions. Use them if required -\n",
        "    {\n",
        "        \"name\": \"get_stock_price\",\n",
        "        \"description\": \"Get the current stock price of a company\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"company_name\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The name of the company\"\n",
        "                },\n",
        "                \"exchange\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The stock exchange where the company is listed\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\n",
        "                \"company_name\",\n",
        "                \"exchange\"\n",
        "            ]\n",
        "        }\n",
        "    }\"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt.strip()}\n",
        "    ]\n",
        "\n",
        "    transformed_data = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False)\n",
        "    print(transformed_data)\n",
        "\n",
        "    eos_token_id = tokenizer.eos_token_id\n",
        "    print(eos_token_id)\n",
        "    inputs = tokenizer([transformed_data], return_tensors=\"pt\").to(runtimeFlag)\n",
        "\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "    _  = model.generate(\n",
        "        **inputs,\n",
        "        streamer=streamer,\n",
        "        max_new_tokens=128,\n",
        "        eos_token_id=eos_token_id,\n",
        "        early_stopping=True,\n",
        "      )"
      ],
      "metadata": {
        "id": "qpQM-3yLvcKZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream(\"Hi, can you tell me the current stock price of Apple on NASDAQ?\")"
      ],
      "metadata": {
        "id": "SWkquySGvdlS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}