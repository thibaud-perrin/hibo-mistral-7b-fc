{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d10bb79-e897-4116-9146-f668877d3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging, TextStreamer\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "import os, torch, wandb, platform, warnings\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34354fe2-0703-4a3c-a8b8-3653ce4ec022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a sharded model to fine-tune in the free version of Google Colab.\n",
    "base_model = \"mistralai/Mistral-7B-v0.1\" #bn22/Mistral-7B-Instruct-v0.1-sharded\n",
    "dataset_name, new_model = \"thibaud-perrin/hibo-function-calling-v1\", \"thibaud-perrin/hibo-mistral-7b-fc-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922f7b9e-21a9-4b46-8a0a-2a59b034a7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3151954319e2449d9c8ad2839a9f2496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e70e9744fa9464880dd4cfd43ed75cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/222M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3ed24c88b94db19dbc8d04a332023c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The conversation between Human and AI assisatance named Gathnex [INST] Generate a headline given a content block.\\nThe Sony Playstation 5 is the latest version of the console. It has improved graphics and faster processing power.\\n[/INST] Experience Amazing Graphics and Speed with the New Sony Playstation 5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading a Gath_baize dataset\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "dataset[\"chat_sample\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc3d9c-c591-4314-8de8-171181e885c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model(Mistral 7B)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit= True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant= False,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n",
    "model.config.pretraining_tp = 1\n",
    "model.gradient_checkpointing_enable()\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.add_bos_token, tokenizer.add_eos_token"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
