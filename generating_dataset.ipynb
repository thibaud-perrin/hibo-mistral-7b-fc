{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f44947-3703-400b-bf26-03d7964f3274",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d10bb79-e897-4116-9146-f668877d3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict, load_from_disk, concatenate_datasets\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dcc3b3-9fd0-4f82-9bf1-1437268e266a",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "589acac7-b16b-4c08-b6f1-9d3b1e0c0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_GATH_BAIZE = True\n",
    "SAVE_GLAIVE_FC_V2 = True\n",
    "MERGE_BOTH = True\n",
    "FINAL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c42b282-8fd9-46c4-8d32-fa0a97e1d365",
   "metadata": {},
   "source": [
    "## Dataset Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34354fe2-0703-4a3c-a8b8-3653ce4ec022",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name, dataset_name2 = \"gathnex/Gath_baize\", \"glaiveai/glaive-function-calling-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b0aaf0-e07a-4abb-8897-1445b27c3d11",
   "metadata": {},
   "source": [
    "## Gath_baize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "922f7b9e-21a9-4b46-8a0a-2a59b034a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a Gath_baize dataset\n",
    "dataset = load_dataset(dataset_name, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "854600b4-a353-4f05-aa94-1901eefc7c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['chat_sample', 'dataset_origin'],\n",
      "    num_rows: 210311\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The conversation between Human and AI assisatance named Gathnex [INST] I would like to know how to find the path with the maximum minimal weight in a graph.\\n[/INST] That\\'s a great question. To find the path with the maximum minimal weight in a graph, you can use the algorithm called \"Floyd–Warshall algorithm\". Have you heard about it before?\\n[INST] Yes, I have. Can you explain how it works?\\n[/INST] Sure. The Floyd–Warshall algorithm is a dynamic programming algorithm that finds the shortest paths in a weighted graph with positive or negative edge weights. It does this by repeatedly improving an estimate of the shortest path between two points, until the estimate is optimal.\\n[INST] How does it guarantee to find the maximum minimal weight path?\\n[/INST] The algorithm works by computing a matrix of all the possible pairwise shortest paths. From that matrix, we can pick the path with the largest minimum weight. That path will be the maximum minimal weight path.\\n[INST] That sounds interesting. Are there any limitations to using this algorithm?\\n[/INST] Yes, there are some limitations. The main limitation is that the Floyd–Warshall algorithm has a time complexity of O(n^3). This means that it can become very slow for very large graphs. Another limitation is that it is not suitable for finding the shortest path in a graph with negative cycles.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset)\n",
    "dataset[\"chat_sample\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e339b13-fc55-4059-91e4-3f3ae10dcd3e",
   "metadata": {},
   "source": [
    "### Function to split System and chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197a9ecb-a480-4b67-89ad-1385fd6fb2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_row(row: str) -> Dict[str, str]:\n",
    "    regex = r\"(?P<system>^.+?)(?=\\[INST\\])|\\[INST\\](?P<user>.+?)\\[\\/INST\\]|(?<=\\[\\/INST\\])(?P<assistant>.+?)(?=\\[INST\\]|$)\"\n",
    "    # Compile the regex for better performance\n",
    "    compiled_regex = re.compile(regex, re.DOTALL)\n",
    "    # Search for matches\n",
    "    matches = compiled_regex.finditer(row)\n",
    "\n",
    "    system_prompt = \"\"\n",
    "    conversation = \"\"\n",
    "    # Process matches\n",
    "    for match in matches:\n",
    "        if match.group(\"system\"):\n",
    "            system = match.group(\"system\").strip()\n",
    "            system_prompt = f\"SYSTEM: The conversation between Human and AI assistant\"\n",
    "        if match.group(\"user\"):\n",
    "            user = match.group(\"user\").strip()\n",
    "            conversation += f\"USER: {user}\\n\\n\\n\"\n",
    "        if match.group(\"assistant\"):\n",
    "            assistant = match.group(\"assistant\").strip()\n",
    "            conversation += f\"ASSISTANT: {assistant} <|endoftext|>\\n\\n\\n\"\n",
    "    \n",
    "    return {'system': system_prompt, 'chat': conversation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d08616-0cde-4aeb-b27e-f8e59059998b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'system': 'SYSTEM: The conversation between Human and AI assistant',\n",
       " 'chat': 'USER: I would like to know how to find the path with the maximum minimal weight in a graph.\\n\\n\\nASSISTANT: That\\'s a great question. To find the path with the maximum minimal weight in a graph, you can use the algorithm called \"Floyd–Warshall algorithm\". Have you heard about it before? <|endoftext|>\\n\\n\\nUSER: Yes, I have. Can you explain how it works?\\n\\n\\nASSISTANT: Sure. The Floyd–Warshall algorithm is a dynamic programming algorithm that finds the shortest paths in a weighted graph with positive or negative edge weights. It does this by repeatedly improving an estimate of the shortest path between two points, until the estimate is optimal. <|endoftext|>\\n\\n\\nUSER: How does it guarantee to find the maximum minimal weight path?\\n\\n\\nASSISTANT: The algorithm works by computing a matrix of all the possible pairwise shortest paths. From that matrix, we can pick the path with the largest minimum weight. That path will be the maximum minimal weight path. <|endoftext|>\\n\\n\\nUSER: That sounds interesting. Are there any limitations to using this algorithm?\\n\\n\\nASSISTANT: Yes, there are some limitations. The main limitation is that the Floyd–Warshall algorithm has a time complexity of O(n^3). This means that it can become very slow for very large graphs. Another limitation is that it is not suitable for finding the shortest path in a graph with negative cycles. <|endoftext|>\\n\\n\\n'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_row(dataset[\"chat_sample\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ed04e-b242-47b5-a12e-842ed278411c",
   "metadata": {},
   "source": [
    "### Splitting System and Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94b7de38-55eb-4fb3-9a29-84eff9708e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa9317a4ad94c8b87dbab75bdc41442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/210311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['dataset_origin', 'system', 'chat'],\n",
      "    num_rows: 210311\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "if SAVE_GATH_BAIZE:\n",
    "    # Use the .map() method to apply convert_row to each row\n",
    "    # Set batched=True if your convert_row function can handle batch processing for efficiency\n",
    "    updated_dataset = dataset.map(lambda examples: convert_row(examples['chat_sample']), remove_columns=['chat_sample'])\n",
    "    \n",
    "    print(updated_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aa8b4d0-8540-4c61-90b8-1985e8c21a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_origin': 'alpaca', 'system': 'SYSTEM: The conversation between Human and AI assistant', 'chat': 'USER: Generate a headline given a content block.\\nThe Sony Playstation 5 is the latest version of the console. It has improved graphics and faster processing power.\\n\\n\\nASSISTANT: Experience Amazing Graphics and Speed with the New Sony Playstation 5 <|endoftext|>\\n\\n\\n'}\n"
     ]
    }
   ],
   "source": [
    "if SAVE_GATH_BAIZE:\n",
    "    print(updated_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc93a0ae-ee1d-41ce-8b88-542e8b2774f9",
   "metadata": {},
   "source": [
    "### Saving new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a26ec68-b1af-4b1b-9e26-a7cabf66389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path where you want to save the dataset\n",
    "save_path = './dataset/hibo-gath_baize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ac38881-04a2-4004-9feb-8d0377de9c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6827bf235b1f4568a442d29f1f15f442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/210311 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to ./dataset/hibo-gath_baize\n"
     ]
    }
   ],
   "source": [
    "if SAVE_GATH_BAIZE:\n",
    "    # Save the dataset to disk\n",
    "    updated_dataset.save_to_disk(save_path)\n",
    "    \n",
    "    print(f\"Dataset saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0fc8c-4fa1-40a9-9352-fa76c60a8d80",
   "metadata": {},
   "source": [
    "### Reloading new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9316c353-921f-44ec-807b-f38b5bb4e885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['dataset_origin', 'system', 'chat'],\n",
      "    num_rows: 210311\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dataset_origin': 'alpaca',\n",
       " 'system': 'SYSTEM: The conversation between Human and AI assistant',\n",
       " 'chat': 'USER: Generate a headline given a content block.\\nThe Sony Playstation 5 is the latest version of the console. It has improved graphics and faster processing power.\\n\\n\\nASSISTANT: Experience Amazing Graphics and Speed with the New Sony Playstation 5 <|endoftext|>\\n\\n\\n'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from disk\n",
    "reloaded_dataset = load_from_disk(save_path)\n",
    "\n",
    "print(reloaded_dataset)\n",
    "reloaded_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f78ed57-8400-44ce-8b7c-ea01cb5dd7ba",
   "metadata": {},
   "source": [
    "## glaive-function-calling-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d79e0d7-11db-4945-84e9-026413febe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a Gath_baize_function_calling dataset\n",
    "dataset2 = load_dataset(dataset_name2, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fbd9d1a-4523-4580-9fd5-d34bd594fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['chat', 'system'],\n",
      "    num_rows: 112960\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat': \"USER: Can you book a flight for me from New York to London?\\n\\n\\nASSISTANT: I'm sorry, but I don't have the capability to book flights. My current function allows me to get the exchange rate between two currencies. If you need help with that, feel free to ask! <|endoftext|>\\n\\n\\n\",\n",
       " 'system': 'SYSTEM: You are a helpful assistant with access to the following functions. Use them if required -\\n{\\n    \"name\": \"get_exchange_rate\",\\n    \"description\": \"Get the exchange rate between two currencies\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"base_currency\": {\\n                \"type\": \"string\",\\n                \"description\": \"The currency to convert from\"\\n            },\\n            \"target_currency\": {\\n                \"type\": \"string\",\\n                \"description\": \"The currency to convert to\"\\n            }\\n        },\\n        \"required\": [\\n            \"base_currency\",\\n            \"target_currency\"\\n        ]\\n    }\\n}\\n'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset2)\n",
    "dataset2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c09394df-d841-4b91-8de9-e5f589717259",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_GLAIVE_FC_V2:\n",
    "    # Adding 'dataset_origin' column directly within the .map() call\n",
    "    updated_dataset = dataset2.map(lambda examples: {'dataset_origin': 'glaiveai/glaive-function-calling-v2'}, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d2aa3e1-5520-47d6-8c9c-e12a1c5b2ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat': \"USER: Can you book a flight for me from New York to London?\\n\\n\\nASSISTANT: I'm sorry, but I don't have the capability to book flights. My current function allows me to get the exchange rate between two currencies. If you need help with that, feel free to ask! <|endoftext|>\\n\\n\\n\", 'system': 'SYSTEM: You are a helpful assistant with access to the following functions. Use them if required -\\n{\\n    \"name\": \"get_exchange_rate\",\\n    \"description\": \"Get the exchange rate between two currencies\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"base_currency\": {\\n                \"type\": \"string\",\\n                \"description\": \"The currency to convert from\"\\n            },\\n            \"target_currency\": {\\n                \"type\": \"string\",\\n                \"description\": \"The currency to convert to\"\\n            }\\n        },\\n        \"required\": [\\n            \"base_currency\",\\n            \"target_currency\"\\n        ]\\n    }\\n}\\n', 'dataset_origin': 'glaiveai/glaive-function-calling-v2'}\n"
     ]
    }
   ],
   "source": [
    "if SAVE_GLAIVE_FC_V2:\n",
    "    print(updated_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2308b8-0279-47d3-8014-66875715d9fb",
   "metadata": {},
   "source": [
    "### Saving new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c836331a-0fc4-478d-ab51-f7af5bc3e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path where you want to save the dataset\n",
    "save_path = './dataset/hibo-glaive-function-calling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a6f494f-41fb-40bf-98ad-7331cdf3282d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1417ba46254f0eb7626801c3b0281d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/112960 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to ./dataset/hibo-glaive-function-calling\n"
     ]
    }
   ],
   "source": [
    "if SAVE_GLAIVE_FC_V2:\n",
    "    # Save the dataset to disk\n",
    "    updated_dataset.save_to_disk(save_path)\n",
    "    \n",
    "    print(f\"Dataset saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e6659e-537b-480c-8496-319a7c784a2b",
   "metadata": {},
   "source": [
    "### Reloading new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53dc39d1-ea29-4445-80cd-7705bc6d29bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['chat', 'system', 'dataset_origin'],\n",
      "    num_rows: 112960\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat': \"USER: Can you book a flight for me from New York to London?\\n\\n\\nASSISTANT: I'm sorry, but I don't have the capability to book flights. My current function allows me to get the exchange rate between two currencies. If you need help with that, feel free to ask! <|endoftext|>\\n\\n\\n\",\n",
       " 'system': 'SYSTEM: You are a helpful assistant with access to the following functions. Use them if required -\\n{\\n    \"name\": \"get_exchange_rate\",\\n    \"description\": \"Get the exchange rate between two currencies\",\\n    \"parameters\": {\\n        \"type\": \"object\",\\n        \"properties\": {\\n            \"base_currency\": {\\n                \"type\": \"string\",\\n                \"description\": \"The currency to convert from\"\\n            },\\n            \"target_currency\": {\\n                \"type\": \"string\",\\n                \"description\": \"The currency to convert to\"\\n            }\\n        },\\n        \"required\": [\\n            \"base_currency\",\\n            \"target_currency\"\\n        ]\\n    }\\n}\\n',\n",
       " 'dataset_origin': 'glaiveai/glaive-function-calling-v2'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from disk\n",
    "reloaded_dataset2 = load_from_disk(save_path)\n",
    "\n",
    "print(reloaded_dataset2)\n",
    "reloaded_dataset2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b61d07-278e-4100-80f9-ace95ebb5e8a",
   "metadata": {},
   "source": [
    "## hibo-function-calling-v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f76ac2c-a0f0-4738-90fa-379b436c4d6b",
   "metadata": {},
   "source": [
    "### Merge both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fdbd259-ab35-47f8-850b-c9972b13806a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: The conversation between Human and AI assistant\n"
     ]
    }
   ],
   "source": [
    "print(reloaded_dataset['system'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83ae1e3c-39ae-4040-a033-f704f54a0fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: You are a helpful assistant with access to the following functions. Use them if required -\n",
      "{\n",
      "    \"name\": \"get_news_headlines\",\n",
      "    \"description\": \"Get the latest news headlines\",\n",
      "    \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "            \"country\": {\n",
      "                \"type\": \"string\",\n",
      "                \"description\": \"The country for which to fetch news\"\n",
      "            }\n",
      "        },\n",
      "        \"required\": [\n",
      "            \"country\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reloaded_dataset2['system'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b45a2c73-a634-4911-9a34-34443e938bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['dataset_origin', 'system', 'chat'],\n",
      "    num_rows: 323271\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "if MERGE_BOTH:\n",
    "    # Assuming updated_dataset and updated_dataset_with_origin are your two datasets ready to be merged\n",
    "    merged_dataset = concatenate_datasets([reloaded_dataset, reloaded_dataset2])\n",
    "    \n",
    "    print(merged_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b67f92-0024-49de-a377-f62b79b71ef2",
   "metadata": {},
   "source": [
    "### Saving merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53f45af3-1bb5-4fba-8305-1696c376dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path where you want to save the dataset\n",
    "save_path = './dataset/hibo-function-calling-merge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d7070ca-713a-4784-ab1d-ea9dff1dbd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fae7fd437854b85adc3901c5f08c582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/323271 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to ./dataset/hibo-function-calling-merge\n"
     ]
    }
   ],
   "source": [
    "if MERGE_BOTH:\n",
    "    # Save the dataset to disk\n",
    "    merged_dataset.save_to_disk(save_path)\n",
    "    \n",
    "    print(f\"Dataset saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48337801-c99d-44bb-b54c-cf78d626b536",
   "metadata": {},
   "source": [
    "### Reloading new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d92f54d0-f41d-4b64-8ded-0a3e168d6ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['dataset_origin', 'system', 'chat'],\n",
      "    num_rows: 323271\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from disk\n",
    "reloaded_dataset3 = load_from_disk(save_path)\n",
    "print(reloaded_dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d3a5d00-40a0-4b54-b8be-2e71c97ecae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_origin': 'alpaca',\n",
       " 'system': 'SYSTEM: The conversation between Human and AI assistant',\n",
       " 'chat': 'USER: Generate a headline given a content block.\\nThe Sony Playstation 5 is the latest version of the console. It has improved graphics and faster processing power.\\n\\n\\nASSISTANT: Experience Amazing Graphics and Speed with the New Sony Playstation 5 <|endoftext|>\\n\\n\\n'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_dataset3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2da0353-4cae-490f-9960-110f7ace0fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_origin': 'glaiveai/glaive-function-calling-v2',\n",
       " 'system': 'SYSTEM: You are a helpful assistant, with no access to external functions.\\n\\n',\n",
       " 'chat': 'USER: How can the efficiency of an algorithm be measured in terms of time complexity? Can you provide an example in [Java code] and calculate its Big O notation? \\n[Formula]: \\nT(n) = O(f(n))\\n[Java code]:\\nint sum = 0;\\nfor (int i = 0; i < n; i++) {\\n for (int j = 0; j < n; j++) {\\n sum++;\\n }\\n}\\nSystem.out.println(sum);\\n[Formula calculation]:\\nT(n) = O(n^2)\\n\\nASSISTANT: The efficiency of an algorithm can be measured in terms of time complexity by analyzing the amount of time it takes to run the algorithm as the input size grows larger. This is typically done by calculating the Big O notation of the algorithm, which provides an upper bound on the time complexity in terms of the input size.\\nIn the example Java code you provided, the algorithm is calculating the sum of all possible pairs of integers from 0 to n-1. The outer loop runs n times, and the inner loop runs n times for each iteration of the outer loop. Therefore, the total number of iterations is n * n, or n^2.\\nThe time complexity of this algorithm can be expressed as T(n) = O(n^2), which means that the running time of the algorithm grows no faster than a quadratic function of the input size n.\\nThis algorithm has a time complexity of O(n^2) because the number of iterations is proportional to the square of the input size. As n grows larger, the running time of the algorithm will increase exponentially. Therefore, this algorithm is not very efficient for large input sizes. <|endoftext|>\\n\\nUSER: Can you explain the difference between supervised and unsupervised machine learning?\\n\\nASSISTANT: Sure! The main difference between supervised and unsupervised machine learning is the presence or absence of labeled data during training. In supervised learning, the data is labeled with the correct output, and the algorithm learns to map inputs to outputs. In contrast, in unsupervised learning, there are no labels, and the algorithm tries to find patterns or structure in the data. <|endoftext|>\\n\\nUSER: Can you give an example of a problem that can be solved using reinforcement learning?\\n\\nASSISTANT: Reinforcement learning is a type of machine learning where agents learn through trial-and-error interactions with an environment to maximize a reward signal. One example of a problem that can be solved using reinforcement learning is training a robot to walk. The robot interacts with its environment by taking actions, such as moving its legs, and receives feedback in the form of a reward signal based on how well it achieves its objective, which is to move forward without falling over. Through repeated interactions, the robot learns to adjust its actions to maximize the reward signal, ultimately learning to walk effectively. <|endoftext|>\\n\\nUSER: Can you explain the concept of overfitting in machine learning?\\n\\nASSISTANT: Overfitting is a common problem in machine learning where a model fits the training data too closely, to the point where it starts to memorize the noise in the data instead of learning the underlying patterns. This can lead to poor generalization performance when the model is applied to new, unseen data. Overfitting occurs when a model is too complex for the available data or when the training data is not representative of the true underlying distribution of the data. To avoid overfitting, techniques such as regularization, early stopping, and cross-validation can be used. <|endoftext|>\\n\\nUSER: Can you explain the difference between deep learning and traditional machine learning algorithms?\\n\\nASSISTANT: Deep learning is a subset of machine learning that uses neural networks with multiple layers to learn features and make predictions. Traditional machine learning algorithms typically require the manual selection of relevant features, whereas deep learning algorithms can automatically learn useful representations from the raw input data. Deep learning has been particularly successful in tasks such as image classification, speech recognition, and natural language processing. However, deep learning algorithms are typically more complex and computationally intensive than traditional machine learning algorithms and require large amounts of training data. <|endoftext|>'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_dataset3[300000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04bc78d-eaed-4e75-9c1d-b02091b00425",
   "metadata": {},
   "source": [
    "## Split train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7f94a89-dd94-46f0-a6e0-c05fb6e8e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    'train': reloaded_dataset3\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0021828a-3465-4364-8b60-dbdd4b0108d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dataset_origin', 'system', 'chat'],\n",
       "        num_rows: 323271\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5097b85-2dea-40a2-9e40-dabd2d2255c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path where you want to save the dataset\n",
    "save_path = './dataset/hibo-function-calling-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "102eaa9e-2eaa-4431-9398-09247d0d46de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce045d623f194f6599f265f507f2470a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/323271 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to ./dataset/hibo-function-calling-v1\n"
     ]
    }
   ],
   "source": [
    "if FINAL:\n",
    "    # Save the dataset to disk\n",
    "    dataset_dict.save_to_disk(save_path)\n",
    "    \n",
    "    print(f\"Dataset saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf2c5ecf-dc8e-4ddb-83f2-7d2fddc99aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabd3cde6f9c4ebaab24ad06c9b84e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6139155d4f45ef981449a2350c9bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/324 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3e9e1db15543859d43cade427868da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiba\\.virtualenvs\\mistral-7b-instruct-CB05KjAH\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\thiba\\.cache\\huggingface\\hub\\datasets--thibaud-perrin--hibo-function-calling-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "if FINAL:\n",
    "    dataset_dict.push_to_hub(\"thibaud-perrin/hibo-function-calling-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0f1cb-8e43-49ae-ad6b-0a4e6b04048e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
